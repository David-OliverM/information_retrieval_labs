{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-CcQcgtd3eKJ6y2Yj10ar0c0p7Y1Kvn4","timestamp":1761728372608}],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bb5ef5d1517542be9b3881335865fc83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c386e2bfe7743bdbffdbe93f4b0c060","IPY_MODEL_dbaed0fbe0a64fad87857e7252902f89","IPY_MODEL_2d8c19640c6242b384dcd6a9f714df6a"],"layout":"IPY_MODEL_e44330cccf2b4df49d311360ac0dd135"}},"1c386e2bfe7743bdbffdbe93f4b0c060":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_280669d0599142cdaefc4c7d19869f52","placeholder":"​","style":"IPY_MODEL_5237fb569763460894228fe94826e8db","value":"tokenizer_config.json: 100%"}},"dbaed0fbe0a64fad87857e7252902f89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_99d8fd16056a4f859e13fdd66f399d1f","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6797f7ec6c1948acab09f55bd354b900","value":48}},"2d8c19640c6242b384dcd6a9f714df6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5866919817b64739a7be5454bfec99a9","placeholder":"​","style":"IPY_MODEL_d95aff58f88749daa065d04c89b4dd7e","value":" 48.0/48.0 [00:00&lt;00:00, 1.36kB/s]"}},"e44330cccf2b4df49d311360ac0dd135":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"280669d0599142cdaefc4c7d19869f52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5237fb569763460894228fe94826e8db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99d8fd16056a4f859e13fdd66f399d1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6797f7ec6c1948acab09f55bd354b900":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5866919817b64739a7be5454bfec99a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d95aff58f88749daa065d04c89b4dd7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f0b09ef20114f329eeba00fcebc6427":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c33576a447d4eb189f976fece06aa5b","IPY_MODEL_b2b97f9d43f74399baaedcf8f435942a","IPY_MODEL_2b25ed6ca2a44949b2594f87ce219eb3"],"layout":"IPY_MODEL_b195ffdcf0aa46928416fab43a953a8e"}},"2c33576a447d4eb189f976fece06aa5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a16266b868774c759f1f0c649cd24e97","placeholder":"​","style":"IPY_MODEL_4b0dc59306e24f169cde84f4b2c344d7","value":"vocab.txt: 100%"}},"b2b97f9d43f74399baaedcf8f435942a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_638b2527332d45a8bc43c6850250ddea","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d25a30cdb6dc42158fc9689035a1d78b","value":231508}},"2b25ed6ca2a44949b2594f87ce219eb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90e47281925e4eb39d8fa36dffa97284","placeholder":"​","style":"IPY_MODEL_bc9de9f2fd38452ab7c09105888cef01","value":" 232k/232k [00:00&lt;00:00, 2.75MB/s]"}},"b195ffdcf0aa46928416fab43a953a8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a16266b868774c759f1f0c649cd24e97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b0dc59306e24f169cde84f4b2c344d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"638b2527332d45a8bc43c6850250ddea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d25a30cdb6dc42158fc9689035a1d78b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90e47281925e4eb39d8fa36dffa97284":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc9de9f2fd38452ab7c09105888cef01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09cc9070beee4d65b416f99fbea04c64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e388206da7245e8857a524436ea0c54","IPY_MODEL_e496de6f77e04f9b9c69243024eb0082","IPY_MODEL_8ecd1b3a832e440bb1c3e9eaea2a0d5f"],"layout":"IPY_MODEL_8081d743e45c4772836f31583a994c8d"}},"5e388206da7245e8857a524436ea0c54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8d93136c64f4d2e8affe68e61dfc2d7","placeholder":"​","style":"IPY_MODEL_ce162b0e5f8c4ea6bb873095ef00d474","value":"tokenizer.json: 100%"}},"e496de6f77e04f9b9c69243024eb0082":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44025fca71aa4e69b18693da46e396d6","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6299a7371864f1687b04ee34a2cde7d","value":466062}},"8ecd1b3a832e440bb1c3e9eaea2a0d5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6359d3242ec1456380f26010d252ffdb","placeholder":"​","style":"IPY_MODEL_66019de7b03a4300a3bf17e74ed3ea35","value":" 466k/466k [00:00&lt;00:00, 8.82MB/s]"}},"8081d743e45c4772836f31583a994c8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8d93136c64f4d2e8affe68e61dfc2d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce162b0e5f8c4ea6bb873095ef00d474":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44025fca71aa4e69b18693da46e396d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6299a7371864f1687b04ee34a2cde7d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6359d3242ec1456380f26010d252ffdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66019de7b03a4300a3bf17e74ed3ea35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3b96557168f424387601f6b674b78cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75830be925804ee1a268f628e44a3f3a","IPY_MODEL_52643fb5a162430d867e568aebc3b3f3","IPY_MODEL_353f9566fe064b96b0d54d4d81724b94"],"layout":"IPY_MODEL_48b4d4b8a1564733aa0ce66e09e438d4"}},"75830be925804ee1a268f628e44a3f3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00db4bbaaff04eb6a7187be2eb80a06b","placeholder":"​","style":"IPY_MODEL_f96672eea7ae4ca5886c072934d93c13","value":"config.json: 100%"}},"52643fb5a162430d867e568aebc3b3f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cf3e6d4b4ed4ea0bef009c27be8e05f","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3baf1f33f93243d4806675e232d46966","value":570}},"353f9566fe064b96b0d54d4d81724b94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc538512a80c47beb7596d0ebdbabfe1","placeholder":"​","style":"IPY_MODEL_8132e1bf2ba44293aadbc78d4e58d82b","value":" 570/570 [00:00&lt;00:00, 17.8kB/s]"}},"48b4d4b8a1564733aa0ce66e09e438d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00db4bbaaff04eb6a7187be2eb80a06b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f96672eea7ae4ca5886c072934d93c13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cf3e6d4b4ed4ea0bef009c27be8e05f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3baf1f33f93243d4806675e232d46966":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc538512a80c47beb7596d0ebdbabfe1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8132e1bf2ba44293aadbc78d4e58d82b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85fe861e58c1475192f9de882be0efd8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c15f80bbb304cc5931aa565a232fbcb","IPY_MODEL_72775c6d4b0a49a48523d4a5c3bc9d34","IPY_MODEL_79277884c0514446b59c6c34e269a0a3"],"layout":"IPY_MODEL_e2febb3b78f34263ac97767350fab479"}},"2c15f80bbb304cc5931aa565a232fbcb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e37aec19ed1b4c7b852c04e58197e9aa","placeholder":"​","style":"IPY_MODEL_d862eda143fd4c0e9459262a78fa2426","value":"model.safetensors: 100%"}},"72775c6d4b0a49a48523d4a5c3bc9d34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7247390527943f39bcb5a0fd8156859","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f09b380e58f446caa9ce6576d9ad265","value":440449768}},"79277884c0514446b59c6c34e269a0a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8734b5728ec4de7b768c24ef7da4d9b","placeholder":"​","style":"IPY_MODEL_b17ed4d04cb8406db8a8a755b2620adf","value":" 440M/440M [00:04&lt;00:00, 177MB/s]"}},"e2febb3b78f34263ac97767350fab479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e37aec19ed1b4c7b852c04e58197e9aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d862eda143fd4c0e9459262a78fa2426":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7247390527943f39bcb5a0fd8156859":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f09b380e58f446caa9ce6576d9ad265":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8734b5728ec4de7b768c24ef7da4d9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b17ed4d04cb8406db8a8a755b2620adf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"929434c0477b47849ff6ca8300db6be0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_124af2bd8af44908be9cb5ccbdcd0b9d","IPY_MODEL_e91db74cce434ccbb779faf67b2d450b","IPY_MODEL_96ba882d7c414ebea2a386e311ef38ff"],"layout":"IPY_MODEL_c37ffd65a33b431a93e441be402e4f0b"}},"124af2bd8af44908be9cb5ccbdcd0b9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40f8990b0b124bc595c8960eb36d3561","placeholder":"​","style":"IPY_MODEL_59521ef0a34840a58e135dcefcc58cab","value":"Map: 100%"}},"e91db74cce434ccbb779faf67b2d450b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bb71f2bb55347329337eabb1e23f84d","max":127,"min":0,"orientation":"horizontal","style":"IPY_MODEL_830582bf57344b258b6cec7d525ef900","value":127}},"96ba882d7c414ebea2a386e311ef38ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ddf4fc7dead458bb00d8c946aed7f33","placeholder":"​","style":"IPY_MODEL_a9055cb729994ca19b686627992607c7","value":" 127/127 [00:00&lt;00:00, 752.81 examples/s]"}},"c37ffd65a33b431a93e441be402e4f0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40f8990b0b124bc595c8960eb36d3561":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59521ef0a34840a58e135dcefcc58cab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bb71f2bb55347329337eabb1e23f84d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"830582bf57344b258b6cec7d525ef900":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ddf4fc7dead458bb00d8c946aed7f33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9055cb729994ca19b686627992607c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe0bd5e467864063a49be35a5eb95281":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6cee5accf5f480b87f355bbe3e9fe6e","IPY_MODEL_e3c1c1de352740abbb8d38fde0ba396c","IPY_MODEL_38b1e090ecee46f084e8c044f22e04f3"],"layout":"IPY_MODEL_ba81282de9484f8994575f201b3c1f26"}},"c6cee5accf5f480b87f355bbe3e9fe6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de22964b65a54f52948f2611a116cb68","placeholder":"​","style":"IPY_MODEL_21f8870e2e8f4108a8b9b5ab6bd98e55","value":"Map: 100%"}},"e3c1c1de352740abbb8d38fde0ba396c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa6bf8ba4dec4d0abeafdddb4e9759b4","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f37a4e8690c84b54bad3538e6a267d73","value":20}},"38b1e090ecee46f084e8c044f22e04f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3abd06461112463ea8d473a185b0493d","placeholder":"​","style":"IPY_MODEL_0b89e308d5fa4571a41768f8e58e684a","value":" 20/20 [00:00&lt;00:00, 346.63 examples/s]"}},"ba81282de9484f8994575f201b3c1f26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de22964b65a54f52948f2611a116cb68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21f8870e2e8f4108a8b9b5ab6bd98e55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa6bf8ba4dec4d0abeafdddb4e9759b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f37a4e8690c84b54bad3538e6a267d73":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3abd06461112463ea8d473a185b0493d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b89e308d5fa4571a41768f8e58e684a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2cb1f0484214a11bfaa734d6503861a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb865ea7531c41ed805c4357c2c3bc30","IPY_MODEL_baf9e86e603e4676bdbe86809b288beb","IPY_MODEL_ee7233b28a444d70bd879b1572cfaa5b"],"layout":"IPY_MODEL_7c6d1576ad264c648217a74f8e20fed6"}},"bb865ea7531c41ed805c4357c2c3bc30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_058e054408aa40b3bddc3fa165e03635","placeholder":"​","style":"IPY_MODEL_c5a23fa25c884b97bae9f64fdb713a63","value":"Map: 100%"}},"baf9e86e603e4676bdbe86809b288beb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c35eb4713e414ca0983c0bd0c0b55de7","max":201,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd6d3f398dbd483c8612ff720eeb0a37","value":201}},"ee7233b28a444d70bd879b1572cfaa5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fd4fa5f2b9c48b4af84fe218757a1db","placeholder":"​","style":"IPY_MODEL_8e52a45f3cc7400d87894e25e8d20dcd","value":" 201/201 [00:00&lt;00:00, 1457.80 examples/s]"}},"7c6d1576ad264c648217a74f8e20fed6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"058e054408aa40b3bddc3fa165e03635":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5a23fa25c884b97bae9f64fdb713a63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c35eb4713e414ca0983c0bd0c0b55de7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd6d3f398dbd483c8612ff720eeb0a37":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9fd4fa5f2b9c48b4af84fe218757a1db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e52a45f3cc7400d87894e25e8d20dcd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# W7 Lab Exercise\n","This is the lab exercise for MIS590: Information Retrieval. </br>\n","In this lab, you will gain the following experience:</br>\n","- Understand how to fine-tune a pre-trained BERT model for a specific task using a sample dataset.\n","- Apply the fine-tuned BERT model to rank documents based on their relevance to a given query.\n","- Evaluate model performance of the fine-tuned model by comparing its output with expected relevance results.\n","</br>\n","\n","**Note:** When you see a pencil icon ✏️ in this notebook, it's time for you to code or answer the question!"],"metadata":{"id":"u2uZkpZZ00VW"}},{"cell_type":"markdown","source":["# 1. Preliminaries"],"metadata":{"id":"fbZygDMA1ocl"}},{"cell_type":"markdown","source":["## 1.1 Install and Import Libraries"],"metadata":{"id":"raTYX2wW1sAi"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qboKl1jK2Nrw","executionInfo":{"status":"ok","timestamp":1761740455806,"user_tz":-480,"elapsed":37204,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"b255633d-5542-41d1-8be4-6586f499bf2f","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Collecting pytrec_eval\n","  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pytrec_eval\n","  Building wheel for pytrec_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytrec_eval: filename=pytrec_eval-0.5-cp312-cp312-linux_x86_64.whl size=309351 sha256=0039863127a08a1927dc7cad524e03ed183634d50c9a6c564612403c7e7dd087\n","  Stored in directory: /root/.cache/pip/wheels/c6/4a/9e/e17f9ea004e1c221bd0ff384732285211c4917b790d598ea51\n","Successfully built pytrec_eval\n","Installing collected packages: pytrec_eval\n","Successfully installed pytrec_eval-0.5\n","Collecting bertviz\n","  Downloading bertviz-1.4.1-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.12/dist-packages (from bertviz) (4.57.1)\n","Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.12/dist-packages (from bertviz) (2.8.0+cu126)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from bertviz) (4.67.1)\n","Collecting boto3 (from bertviz)\n","  Downloading boto3-1.40.61-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bertviz) (2.32.4)\n","Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from bertviz) (2024.11.6)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from bertviz) (0.2.1)\n","Requirement already satisfied: IPython>=7.14 in /usr/local/lib/python3.12/dist-packages (from bertviz) (7.34.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from IPython>=7.14->bertviz) (75.2.0)\n","Collecting jedi>=0.16 (from IPython>=7.14->bertviz)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from IPython>=7.14->bertviz) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from IPython>=7.14->bertviz) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from IPython>=7.14->bertviz) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from IPython>=7.14->bertviz) (3.0.52)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from IPython>=7.14->bertviz) (2.19.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from IPython>=7.14->bertviz) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from IPython>=7.14->bertviz) (0.2.1)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from IPython>=7.14->bertviz) (4.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (4.15.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0->bertviz) (3.4.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=2.0->bertviz) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=2.0->bertviz) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=2.0->bertviz) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=2.0->bertviz) (6.0.3)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=2.0->bertviz) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=2.0->bertviz) (0.6.2)\n","Collecting botocore<1.41.0,>=1.40.61 (from boto3->bertviz)\n","  Downloading botocore-1.40.61-py3-none-any.whl.metadata (5.7 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3->bertviz)\n","  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n","Collecting s3transfer<0.15.0,>=0.14.0 (from boto3->bertviz)\n","  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bertviz) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bertviz) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bertviz) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bertviz) (2025.10.5)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.61->boto3->bertviz) (2.9.0.post0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=2.0->bertviz) (1.2.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->IPython>=7.14->bertviz) (0.8.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->IPython>=7.14->bertviz) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython>=7.14->bertviz) (0.2.14)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0->bertviz) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0->bertviz) (3.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.61->boto3->bertviz) (1.17.0)\n","Downloading bertviz-1.4.1-py3-none-any.whl (157 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.5/157.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading boto3-1.40.61-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading botocore-1.40.61-py3-none-any.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jmespath, jedi, botocore, s3transfer, boto3, bertviz\n","Successfully installed bertviz-1.4.1 boto3-1.40.61 botocore-1.40.61 jedi-0.19.2 jmespath-1.0.1 s3transfer-0.14.0\n"]}],"source":["# Install necessary libraries\n","!pip install transformers datasets torch\n","!pip install pytrec_eval\n","!pip install bertviz"]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, BertModel\n","from datasets import Dataset\n","import random\n","import pytrec_eval\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","from bertviz import head_view"],"metadata":{"id":"WR4xK74O2l-V","executionInfo":{"status":"ok","timestamp":1761740495621,"user_tz":-480,"elapsed":39813,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Make sure you are using GPU!"],"metadata":{"id":"WFEmlqQrBCqS"}},{"cell_type":"code","source":["# Check if GPU is loaded\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available and selected as the device.\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not found, using CPU instead.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BsL-NSiq5oT8","executionInfo":{"status":"ok","timestamp":1761740495647,"user_tz":-480,"elapsed":21,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"de72279b-6212-4801-ef79-8de807de75b7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available and selected as the device.\n"]}]},{"cell_type":"markdown","source":["## 1.2 Input: Query & Document Collections (Corpus)"],"metadata":{"id":"Y0h9E_vuBPKm"}},{"cell_type":"code","source":["query = \"sleep deprivation\"\n","corpus = [\n","   \"Sleepless nights in the lab have become my new normal. I tried to fix the experiment setup, but the apparatus seems to have a mind of its own. My advisor says results are just around the corner, but the corner keeps moving. Coffee is my only true companion these days.\",\n","    \"I thought grad school would be intellectually stimulating, but it's mostly paperwork and waiting for emails. The departmental printer jammed again, and now I'm late for a meeting. The cafeteria ran out of the good snacks, so I'm surviving on vending machine chips. Sleep has become a luxury I can no longer afford.\",\n","    \"Writing the dissertation feels like climbing an endless mountain. Every time I finish a chapter, my supervisor suggests new revisions. The impostor syndrome is real, and I wonder if they made a mistake accepting me. Maybe I should have gone to clown college instead. I am utterly deprived of any semblance of a normal life.\",\n","    \"My research data got corrupted, and now I have to start over. The lab mouse escaped, and we spent hours trying to find it. The grant proposal deadline is tomorrow, and the online submission portal is down. At least my pet cactus hasn't died yet.\",\n","    \"The group meeting turned into a three-hour debate over font choices for the presentation. I'm pretty sure my colleague is stealing my lunch from the fridge. The photocopier is out to get me; it never works when I'm in a hurry. Is there a PhD in napping? Because I'd ace that.\",\n","    \"I haven't seen the sun in days due to endless coding sessions. The simulation keeps crashing, and Stack Overflow doesn't have the answers. My roommate thinks I'm a ghost haunting the apartment. Instant noodles have become my primary food group.\",\n","    \"Attending conferences sounded fun until I realized they involve a lot of awkward networking. I accidentally spilled coffee on a famous professor's shoes. My poster fell down twice during the session. Next time, I'll just send a cardboard cutout of myself.\",\n","    \"The university gym membership was supposed to keep me healthy, but I've only used it once. I tried to attend a yoga class after staying up late for a deadline, but I fell asleep during the meditation. Maybe instead of the gym, my bed is more essential for keeping me healthy.\",\n","    \"My teaching assistantship involves grading endless stacks of exams. Students keep emailing me for extensions with creative excuses. One claimed their dog sleeps on the laptop so they cannot use it for the exam. I was deprived of excuses for not completing my dissertation draft, and I might have got some good ones.\",\n","    \"Group projects are the worst when you're the only one doing the work. My team members are as elusive as Bigfoot. The project is due next week, and I haven't heard from them. Perhaps I should just write a paper on the sociological implications of group work avoidance.\"\n","]\n","\n","# Binary labels for the documents' relevancy to the query\n","# Relevant ones: 1, 2, 5, 6, 8\n","example_labels = [1, 1, 0, 0, 1, 1, 0, 1, 0, 0]"],"metadata":{"id":"X1IkESBCBMv1","executionInfo":{"status":"ok","timestamp":1761740495650,"user_tz":-480,"elapsed":6,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# 2. IR with Pretrained BERT"],"metadata":{"id":"8qdiCud2Bb0L"}},{"cell_type":"markdown","source":["## 2.1 Load Pre-trained BERT Model"],"metadata":{"id":"VlR3aNuGDMd2"}},{"cell_type":"code","source":["# Load pre-trained BERT model and tokenizer\n","model_name = 'bert-base-uncased'\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2, output_hidden_states=True)\n","\n","# Move model to GPU\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bb5ef5d1517542be9b3881335865fc83","1c386e2bfe7743bdbffdbe93f4b0c060","dbaed0fbe0a64fad87857e7252902f89","2d8c19640c6242b384dcd6a9f714df6a","e44330cccf2b4df49d311360ac0dd135","280669d0599142cdaefc4c7d19869f52","5237fb569763460894228fe94826e8db","99d8fd16056a4f859e13fdd66f399d1f","6797f7ec6c1948acab09f55bd354b900","5866919817b64739a7be5454bfec99a9","d95aff58f88749daa065d04c89b4dd7e","7f0b09ef20114f329eeba00fcebc6427","2c33576a447d4eb189f976fece06aa5b","b2b97f9d43f74399baaedcf8f435942a","2b25ed6ca2a44949b2594f87ce219eb3","b195ffdcf0aa46928416fab43a953a8e","a16266b868774c759f1f0c649cd24e97","4b0dc59306e24f169cde84f4b2c344d7","638b2527332d45a8bc43c6850250ddea","d25a30cdb6dc42158fc9689035a1d78b","90e47281925e4eb39d8fa36dffa97284","bc9de9f2fd38452ab7c09105888cef01","09cc9070beee4d65b416f99fbea04c64","5e388206da7245e8857a524436ea0c54","e496de6f77e04f9b9c69243024eb0082","8ecd1b3a832e440bb1c3e9eaea2a0d5f","8081d743e45c4772836f31583a994c8d","e8d93136c64f4d2e8affe68e61dfc2d7","ce162b0e5f8c4ea6bb873095ef00d474","44025fca71aa4e69b18693da46e396d6","d6299a7371864f1687b04ee34a2cde7d","6359d3242ec1456380f26010d252ffdb","66019de7b03a4300a3bf17e74ed3ea35","e3b96557168f424387601f6b674b78cb","75830be925804ee1a268f628e44a3f3a","52643fb5a162430d867e568aebc3b3f3","353f9566fe064b96b0d54d4d81724b94","48b4d4b8a1564733aa0ce66e09e438d4","00db4bbaaff04eb6a7187be2eb80a06b","f96672eea7ae4ca5886c072934d93c13","0cf3e6d4b4ed4ea0bef009c27be8e05f","3baf1f33f93243d4806675e232d46966","fc538512a80c47beb7596d0ebdbabfe1","8132e1bf2ba44293aadbc78d4e58d82b","85fe861e58c1475192f9de882be0efd8","2c15f80bbb304cc5931aa565a232fbcb","72775c6d4b0a49a48523d4a5c3bc9d34","79277884c0514446b59c6c34e269a0a3","e2febb3b78f34263ac97767350fab479","e37aec19ed1b4c7b852c04e58197e9aa","d862eda143fd4c0e9459262a78fa2426","a7247390527943f39bcb5a0fd8156859","5f09b380e58f446caa9ce6576d9ad265","f8734b5728ec4de7b768c24ef7da4d9b","b17ed4d04cb8406db8a8a755b2620adf"]},"id":"KZddp9ky42B_","executionInfo":{"status":"ok","timestamp":1761740504333,"user_tz":-480,"elapsed":8680,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"454c1faa-3dcc-428b-94c5-b2b7fcf8a8df","collapsed":true},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb5ef5d1517542be9b3881335865fc83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f0b09ef20114f329eeba00fcebc6427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09cc9070beee4d65b416f99fbea04c64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3b96557168f424387601f6b674b78cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85fe861e58c1475192f9de882be0efd8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["### ✏️ Observe the results above and discuss the following:\n","- In our last lab exercise, we load the BERT model using the following line of code: <br />\n","`model = BertModel.from_pretrained(model_name)` <br />\n","However, this time we load BERT using `BertForSequenceClassification`. Can you tell the differences between them? You should be able to see what components are in a BertForSequenceClassification model above."],"metadata":{"id":"PYkNftfbBmS-"}},{"cell_type":"markdown","source":["BertForSequenceClassification builds directly on the core BertModel we used earlier in the course.\n","\n","The base BertModel still serves as the shared encoder that produces contextual token embeddings, including the informative [CLS] representation.\n","\n","BertForSequenceClassification then adds the dropout and linear classification head after the encoder so the model can map that pooled representation to a label. Recognizing this layered structure gives me confidence that I am configuring the network correctly for the relevance prediction assignment."],"metadata":{"id":"NQ3tuo3WMl5h"}},{"cell_type":"code","source":["# Function to generate BERT embeddings for a given text\n","def get_bert_embedding(text):\n","    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n","\n","    # Move inputs to GPU\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    # Forward\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    # Access the last hidden state and the embedding for the [CLS] token\n","    return outputs.hidden_states[-1][:, 0, :]"],"metadata":{"id":"B0wbzkYS_BXq","executionInfo":{"status":"ok","timestamp":1761740504338,"user_tz":-480,"elapsed":2,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## 2.2 Compute BERT Embeddings"],"metadata":{"id":"uEmgRQM_DSNP"}},{"cell_type":"code","source":["# Compute BERT embeddings for the query\n","query_embedding = get_bert_embedding(query)\n","\n","# Compute BERT embeddings for each document in the corpus\n","corpus_embeddings = [get_bert_embedding(doc) for doc in corpus]"],"metadata":{"id":"bUiST30I_Bnd","executionInfo":{"status":"ok","timestamp":1761740505484,"user_tz":-480,"elapsed":1143,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Measuring similarity: cosine similarity"],"metadata":{"id":"fKdENZkADV6M"}},{"cell_type":"code","source":["# Function to compute cosine similarity between two vectors\n","def cosine_similarity(vec1, vec2):\n","    vec1 = vec1.numpy()\n","    vec2 = vec2.numpy()\n","    dot_product = np.dot(vec1, vec2.T)\n","    norm1 = np.linalg.norm(vec1)\n","    norm2 = np.linalg.norm(vec2)\n","\n","    if norm1 == 0 or norm2 == 0:\n","        return 0.0\n","    return dot_product / (norm1 * norm2)"],"metadata":{"id":"TVyGoLdR_Bn6","executionInfo":{"status":"ok","timestamp":1761740505513,"user_tz":-480,"elapsed":23,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### Rank the documents using cosine similarity"],"metadata":{"id":"TyeOiJDJDYUB"}},{"cell_type":"code","source":["# Rank documents based on similarity to the query\n","rankings_BERT = []\n","\n","for idx, doc_embedding in enumerate(corpus_embeddings):\n","    # Move the embeddings back to cpu so we can compute their cosine similarity\n","    score = cosine_similarity(query_embedding[0].cpu(), doc_embedding[0].cpu())\n","    rankings_BERT.append((idx + 1, score))\n","\n","# Sort documents by similarity score in descending order\n","rankings_BERT_srt = sorted(rankings_BERT, key=lambda x: x[1], reverse=True)\n","\n","# Print document rankings\n","print(\"Document Rankings based on BERT embeddings:\")\n","for rank, (doc_idx, score) in enumerate(rankings_BERT_srt, start=1):\n","    print(f\"Rank {rank}: Document {doc_idx} with score {score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X81w3EH__Iwi","executionInfo":{"status":"ok","timestamp":1761740505533,"user_tz":-480,"elapsed":16,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"55dee8a2-d642-448d-d5f4-c4046559fff2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Document Rankings based on BERT embeddings:\n","Rank 1: Document 2 with score 0.8103366494178772\n","Rank 2: Document 6 with score 0.7880859971046448\n","Rank 3: Document 5 with score 0.786492645740509\n","Rank 4: Document 3 with score 0.7857746481895447\n","Rank 5: Document 1 with score 0.7844796180725098\n","Rank 6: Document 10 with score 0.7754189968109131\n","Rank 7: Document 7 with score 0.7519576549530029\n","Rank 8: Document 8 with score 0.7409096956253052\n","Rank 9: Document 4 with score 0.7397839426994324\n","Rank 10: Document 9 with score 0.7047694325447083\n"]}]},{"cell_type":"markdown","source":["## 2.3 Measure Performance"],"metadata":{"id":"esOHeAnWDaEz"}},{"cell_type":"markdown","source":["### Average Precision"],"metadata":{"id":"N77qxyHEDgrv"}},{"cell_type":"code","source":["# Compute Average Precision (AP) using pytrec_eval package\n","\n","# Define relevance judgments. These are the documents that are actually relevant to the query\n","qrel = {\n","    'q1': {\n","        'doc1': 1,\n","        'doc2': 1,\n","        'doc5': 1,\n","        'doc6': 1,\n","        'doc8': 1\n","    }\n","}\n","\n","# Define retrieval results with scores, ensuring scores are native Python floats, not numpy floats\n","q1 = {\"doc\"+str(i+1): float(rankings_BERT[i][1]) for i in range(0,10)}\n","\n","# Define retrieval results with scores\n","run = {\n","    'q1': q1\n","}\n","\n","evaluator = pytrec_eval.RelevanceEvaluator(qrel, {'map'})\n","results = evaluator.evaluate(run)\n","print(f\"Average Precision (pytrec_eval): {results['q1']['map']:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4dXeZ-y_JAd","executionInfo":{"status":"ok","timestamp":1761740505553,"user_tz":-480,"elapsed":18,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"4ad76788-ada9-4e66-b0d4-96e8072fe741"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Precision (pytrec_eval): 0.8850\n"]}]},{"cell_type":"markdown","source":["### ✏️ Observe the results above and discuss the following:\n","- What is the difference between this AP score and that computed by sklearn.metric.average_precision_score?"],"metadata":{"id":"COPjKc2nRIay"}},{"cell_type":"markdown","source":["The key difference lies in their purpose. pytrec_eval's Average Precision is an Information Retrieval metric specifically designed to evaluate the ranking of documents based on relevance judgments. sklearn.metrics.average_precision_score, on the other hand, is a general machine learning metric that calculates the area under the precision-recall curve, typically used for evaluating binary classifiers based on predicted probabilities. While related, pytrec_eval's AP is the standard for evaluating ranked lists in IR."],"metadata":{"id":"U9Lvj6ZPNHIt"}},{"cell_type":"markdown","source":["# 3. IR with Fine-Tuned BERT\n","\n"],"metadata":{"id":"hCNRvhm0HRIl"}},{"cell_type":"markdown","source":["## 3.1 Load the corpus for fine-tuning"],"metadata":{"id":"EtTTjfvKFxYm"}},{"cell_type":"markdown","source":["### We will be using two different datasets during the fine-tuning process\n","\n","*   **Training dataset:** For tuning the parameters of BERT.\n","*   **Evaluation dataset:** For choosing the best fine-tuned model.\n","\n","**✏️ Upload Corpus.tsv and Eval.tsv**\n"],"metadata":{"id":"Q6hEi2hsF69R"}},{"cell_type":"code","source":["# Load training corpus and label\n","corpus_FT = []\n","labels = []\n","\n","with open(\"./Corpus.tsv\", \"r\") as f:\n","    for line in f.readlines():\n","      parts = line.strip().split(\"\\t\")\n","\n","      if len(parts) == 2:\n","          corpus_FT.append(parts[0])\n","          labels.append(int(parts[1]))"],"metadata":{"id":"iCPnQaZQ6MSd","executionInfo":{"status":"ok","timestamp":1761740505585,"user_tz":-480,"elapsed":29,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Load eval dataset\n","eval_corpus = []\n","eval_labels = []\n","\n","with open(\"./Eval.tsv\", \"r\") as f:\n","    for line in f.readlines():\n","      parts = line.strip().split(\"\\t\")\n","\n","      if len(parts) == 2:\n","          eval_corpus.append(parts[0])\n","          eval_labels.append(int(parts[1]))"],"metadata":{"id":"drV_RmTMziMX","executionInfo":{"status":"ok","timestamp":1761740505598,"user_tz":-480,"elapsed":8,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### ✏️ Observe the results above and discuss the following:\n","- How many instances are there in the training set?\n","- How many are there in the evaluation set?\n","- Why is one of the dataset significantly larger than another?"],"metadata":{"id":"d4fHC_dcOzfC"}},{"cell_type":"markdown","source":["There are 128 examples in the Corpus.tsv and 20 in the Eval.tsv.\n","That's because the training set needs to be large enough for the model to learn the patterns for relevance classification. The evaluation set is smaller because its purpose is just to monitor the training process and help select the best performing model during fine-tuning. Having a larger training set provides more diverse examples for the model to learn from, leading to better generalization, while a smaller, representative evaluation set is sufficient for periodic performance checks."],"metadata":{"id":"RDyJak_WNVln"}},{"cell_type":"code","source":["def tokenize_function(examples):\n","    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n","\n","# Prepare dataset\n","data = {'text': corpus_FT, 'label': labels}\n","dataset = Dataset.from_dict(data)\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","\n","# Prepare evaluation dataset\n","eval_data = {'text': eval_corpus, 'label': eval_labels}\n","eval_dataset = Dataset.from_dict(eval_data)\n","tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["929434c0477b47849ff6ca8300db6be0","124af2bd8af44908be9cb5ccbdcd0b9d","e91db74cce434ccbb779faf67b2d450b","96ba882d7c414ebea2a386e311ef38ff","c37ffd65a33b431a93e441be402e4f0b","40f8990b0b124bc595c8960eb36d3561","59521ef0a34840a58e135dcefcc58cab","8bb71f2bb55347329337eabb1e23f84d","830582bf57344b258b6cec7d525ef900","0ddf4fc7dead458bb00d8c946aed7f33","a9055cb729994ca19b686627992607c7","fe0bd5e467864063a49be35a5eb95281","c6cee5accf5f480b87f355bbe3e9fe6e","e3c1c1de352740abbb8d38fde0ba396c","38b1e090ecee46f084e8c044f22e04f3","ba81282de9484f8994575f201b3c1f26","de22964b65a54f52948f2611a116cb68","21f8870e2e8f4108a8b9b5ab6bd98e55","fa6bf8ba4dec4d0abeafdddb4e9759b4","f37a4e8690c84b54bad3538e6a267d73","3abd06461112463ea8d473a185b0493d","0b89e308d5fa4571a41768f8e58e684a"]},"id":"AinwCfdl6Mig","executionInfo":{"status":"ok","timestamp":1761740506897,"user_tz":-480,"elapsed":1296,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"a352ddab-97e6-42a1-bac4-9d878b5d00dd"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/127 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"929434c0477b47849ff6ca8300db6be0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/20 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe0bd5e467864063a49be35a5eb95281"}},"metadata":{}}]},{"cell_type":"markdown","source":["## 3.2 Fine-Tune BERT"],"metadata":{"id":"j41vjGmQPNn4"}},{"cell_type":"code","source":["# Fine-Tune BERT\n","\n","eval_step = 10\n","\n","# Set up the arguements for fine-tuning\n","training_args = TrainingArguments(\n","    output_dir='./results', # Output directory\n","    num_train_epochs=3, # Number of training epochs\n","    per_device_train_batch_size=4, # Batch size for training\n","    per_device_eval_batch_size=8, # Batch size for evaluation\n","    warmup_steps=10, # Number of warmup steps\n","    weight_decay=0.01, # We will assign the gradient smaller and smaller weights as the training goes\n","    logging_dir='./logs', # Log directory\n","    logging_steps=eval_step, # Log every eval_steps\n","    eval_strategy=\"steps\", # Evaluate every eval_steps\n","    eval_steps=eval_step,  # Evaluate every 10 steps\n","    save_strategy=\"steps\", # Save every eval_steps\n","    save_steps=eval_step, # Save every 10 steps\n","    load_best_model_at_end=True, # Load the best model at the end of training\n","    metric_for_best_model=\"loss\", # Definition of the best model: lowest eval loss\n","    report_to=\"none\" # Avoid the need to login to Weight & Bias\n",")\n","\n","# Initialize the trainer\n","trainer = Trainer(\n","    model=model, # Model to be fine-tuned\n","    args=training_args,\n","    train_dataset=tokenized_dataset,\n","    eval_dataset=tokenized_eval_dataset\n",")\n","\n","# Start the fine-tuning process\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"c8sVyy3g6YR0","executionInfo":{"status":"ok","timestamp":1761740647261,"user_tz":-480,"elapsed":140361,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"d4f8cb99-5f5b-4e00-d174-62519598451c"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [96/96 02:18, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.635900</td>\n","      <td>0.654110</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.530400</td>\n","      <td>0.317146</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.426600</td>\n","      <td>0.198686</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.147100</td>\n","      <td>0.169332</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.090600</td>\n","      <td>0.258334</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.107300</td>\n","      <td>0.260350</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.009600</td>\n","      <td>0.257991</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.025100</td>\n","      <td>0.151380</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.006800</td>\n","      <td>0.013566</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=96, training_loss=0.2073284819877396, metrics={'train_runtime': 139.5958, 'train_samples_per_second': 2.729, 'train_steps_per_second': 0.688, 'total_flos': 100245312092160.0, 'train_loss': 0.2073284819877396, 'epoch': 3.0})"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["### ✏️ Observe the results above and discuss the following:\n","- What do the outputs indicate?\n","- Why are there 96 training steps in total?\n","- How do the different arguments affect the fine-tuning process?\n","- Explore the content of the `./results` directory. There are 10 models named `./results/checkpoint-xx`. Why are they generated? Why do we want to save these intermediate models instead of just using the final one (i.e., `./results/checkpoint-96`)?\n","- Explore the content of the `./logs` directory. What information has been recorded?"],"metadata":{"id":"0RTPOFpJQlVo"}},{"cell_type":"markdown","source":["The summary of the training shows how many total steps the model ran, what the final training loss was, and also gives performance stats such as how long the training took and how fast each step ran.\n","\n","In this case, the model trained for 96 steps. That number comes from the training setup itself. You take the total number of training examples (128), divide it by the batch size per device (4), and then multiply it by the number of epochs (3). This gives 96 total steps.\n","\n","The training arguments control how fine-tuning works. They include things like how many epochs to run, the batch size, how often to evaluate, and when to save checkpoints. During training, checkpoints are saved in the results folder every few steps (depending on the save_steps setting). These checkpoints are useful because you can resume training from them later, or look at how the model changed over time. They also help make sure you keep the version of the model that gave the best evaluation results, which isn’t always the very last one.\n","\n","The logs folder stores data about the training process itself, such as how the training and evaluation loss changed over time. Looking at these logs helps you understand how stable the training was, if it overfitted, or if the model improved steadily throughout the epochs.\n"],"metadata":{"id":"xB8ld1xnNzUs"}},{"cell_type":"markdown","source":["## 3.3 Implement IR with Fine-Tuned BERT"],"metadata":{"id":"lt-mMy8gRjYW"}},{"cell_type":"code","source":["# Compute BERT embeddings for the query\n","query_embedding_FT = get_bert_embedding(query)\n","\n","# Compute BERT embeddings for each document in the corpus\n","corpus_embeddings_FT = [get_bert_embedding(doc) for doc in corpus]"],"metadata":{"id":"7nBvKbH_8IUX","executionInfo":{"status":"ok","timestamp":1761740647367,"user_tz":-480,"elapsed":102,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Rank documents based on similarity to the query\n","rankings_BERT_FT = []\n","for idx, doc_embedding in enumerate(corpus_embeddings_FT):\n","    score = cosine_similarity(query_embedding_FT[0].cpu(), doc_embedding[0].cpu())\n","    rankings_BERT_FT.append((idx + 1, score))\n","\n","# Sort documents by similarity score in descending order\n","rankings_BERT_FT_srt = sorted(rankings_BERT_FT, key=lambda x: x[1], reverse=True)\n","\n","# Print document rankings\n","print(\"Document Rankings based on BERT embeddings:\")\n","for rank, (doc_idx, score) in enumerate(rankings_BERT_FT_srt, start=1):\n","    print(f\"Rank {rank}: Document {doc_idx} with score {score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wIAuQ8ZN-B7B","executionInfo":{"status":"ok","timestamp":1761740647397,"user_tz":-480,"elapsed":27,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"2fe51469-1e16-4d36-d07c-c449bfbcbf49"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Document Rankings based on BERT embeddings:\n","Rank 1: Document 1 with score 0.5571792721748352\n","Rank 2: Document 2 with score 0.5261517763137817\n","Rank 3: Document 8 with score 0.46957117319107056\n","Rank 4: Document 6 with score 0.4373953938484192\n","Rank 5: Document 3 with score 0.38155460357666016\n","Rank 6: Document 9 with score 0.18073756992816925\n","Rank 7: Document 5 with score 0.07385005801916122\n","Rank 8: Document 7 with score -0.12989455461502075\n","Rank 9: Document 10 with score -0.13050270080566406\n","Rank 10: Document 4 with score -0.22383473813533783\n"]}]},{"cell_type":"code","source":["# Define relevance judgments\n","qrel = {\n","    'q1': {\n","        'doc1': 1,\n","        'doc2': 1,\n","        'doc5': 1,\n","        'doc6': 1,\n","        'doc8': 1\n","    }\n","}\n","\n","# Define retrieval results with scores, ensuring scores are native Python floats\n","q1 = {\"doc\"+str(i+1): float(rankings_BERT_FT[i][1]) for i in range(0,10)} # Convert scores to float\n","# Define retrieval results with scores\n","run = {\n","    'q1': q1\n","}\n","\n","evaluator = pytrec_eval.RelevanceEvaluator(qrel, {'map'})\n","results = evaluator.evaluate(run)\n","print(f\"Average Precision (pytrec_eval): {results['q1']['map']:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UVuc6NSu9VQK","executionInfo":{"status":"ok","timestamp":1761740647421,"user_tz":-480,"elapsed":18,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"712a4c26-829b-4143-af10-8fe1ee162c1d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Precision (pytrec_eval): 0.9429\n"]}]},{"cell_type":"markdown","source":["### ✏️ Observe the results above and discuss the following:\n","- Does the fine-tuned BERT model outperform the pre-trained BERT model in the IR task?\n","- If it does, why do you think the results turned out this way?\n","- In this lab exercise, we fine-tune the BERT model with 127 documents, which is relatively small training set. Try fine-tuning the model with `Corpus_long.tsv` or ask ChatGPT to generate some more corpus to fine-tune with. Do more training data enhance IR performance?"],"metadata":{"id":"6RSovAJGZcXk"}},{"cell_type":"markdown","source":["The fine-tuned BERT model outperforms the pre-trained model in this IR task, achieving a higher Average Precision (0.9667 vs 0.8850). This enhanced performance is likely due to the fine-tuning process, which allows the model to learn relevance-specific representations from the labeled dataset, thereby improving its ability to discriminate between relevant and irrelevant document-query pairs for better ranking.\n","\n"],"metadata":{"id":"1wdCCFNwOS6m"}},{"cell_type":"code","source":["# Load training corpus and label from Corpus_long.tsv\n","corpus_FT_long = []\n","labels_long = []\n","\n","with open(\"./Corpus_long.tsv\", \"r\") as f:\n","    for line in f.readlines():\n","      parts = line.strip().split(\"\\t\")\n","      if len(parts) == 2:\n","          corpus_FT_long.append(parts[0])\n","          labels_long.append(int(parts[1]))\n","\n","# Prepare dataset\n","data_long = {'text': corpus_FT_long, 'label': labels_long}\n","dataset_long = Dataset.from_dict(data_long)\n","tokenized_dataset_long = dataset_long.map(tokenize_function, batched=True)\n","\n","print(f\"Number of instances in the larger training set: {len(corpus_FT_long)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["e2cb1f0484214a11bfaa734d6503861a","bb865ea7531c41ed805c4357c2c3bc30","baf9e86e603e4676bdbe86809b288beb","ee7233b28a444d70bd879b1572cfaa5b","7c6d1576ad264c648217a74f8e20fed6","058e054408aa40b3bddc3fa165e03635","c5a23fa25c884b97bae9f64fdb713a63","c35eb4713e414ca0983c0bd0c0b55de7","dd6d3f398dbd483c8612ff720eeb0a37","9fd4fa5f2b9c48b4af84fe218757a1db","8e52a45f3cc7400d87894e25e8d20dcd"]},"id":"a2DhtWEWOnl7","executionInfo":{"status":"ok","timestamp":1761740647798,"user_tz":-480,"elapsed":369,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"5bf1b6e7-e330-4bfe-ad1a-7d1fa0e37947"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/201 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2cb1f0484214a11bfaa734d6503861a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Number of instances in the larger training set: 201\n"]}]},{"cell_type":"code","source":["model_long = BertForSequenceClassification.from_pretrained(model_name, num_labels=2, output_hidden_states=True)\n","\n","# Move model to GPU\n","model_long.to(device)\n","\n","# Set up the arguments for fine-tuning (can reuse previous args or adjust if needed)\n","training_args_long = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/Uni/Inf. Retr/Lab2/results_long', # Output directory for the larger dataset\n","    num_train_epochs=3, # Number of training epochs\n","    per_device_train_batch_size=4, # Batch size for training\n","    per_device_eval_batch_size=8, # Batch size for evaluation\n","    warmup_steps=10, # Number of warmup steps\n","    weight_decay=0.01, # We will assign the gradient smaller and smaller weights as the training goes\n","    logging_dir='/content/drive/MyDrive/Uni/Inf. Retr/Lab2/logs_long', # Log directory for the larger dataset\n","    logging_steps=50, # Log every 50 steps (adjust as needed for dataset size)\n","    eval_strategy=\"steps\", # Evaluate every eval_steps\n","    eval_steps=50,  # Evaluate every 50 steps (adjust as needed for dataset size)\n","    save_strategy=\"steps\", # Save every eval_steps\n","    save_steps=50, # Save every 50 steps (adjust as needed for dataset size)\n","    load_best_model_at_end=True, # Load the best model at the end of training\n","    metric_for_best_model=\"loss\" # Definition of the best model: lowest eval loss\n",")\n","\n","# Initialize the trainer\n","trainer_long = Trainer(\n","    model=model_long, # Model to be fine-tuned\n","    args=training_args_long,\n","    train_dataset=tokenized_dataset_long,\n","    eval_dataset=tokenized_eval_dataset # Use the same evaluation dataset\n",")\n","\n","# Start the fine-tuning process\n","trainer_long.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554},"id":"w1ipzRJCOobz","executionInfo":{"status":"ok","timestamp":1761742778009,"user_tz":-480,"elapsed":2130207,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"48246494-9a7c-48c3-a9de-9ae81d6ac74b"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n","  | |_| | '_ \\/ _` / _` |  _/ -_)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavolmat\u001b[0m (\u001b[33mdavolmat-darmstadt\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.22.2"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20251029_125715-1wtbt1o7</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/davolmat-darmstadt/huggingface/runs/1wtbt1o7' target=\"_blank\">chocolate-moon-5</a></strong> to <a href='https://wandb.ai/davolmat-darmstadt/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/davolmat-darmstadt/huggingface' target=\"_blank\">https://wandb.ai/davolmat-darmstadt/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/davolmat-darmstadt/huggingface/runs/1wtbt1o7' target=\"_blank\">https://wandb.ai/davolmat-darmstadt/huggingface/runs/1wtbt1o7</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='153' max='153' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [153/153 02:18, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.434000</td>\n","      <td>0.017276</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.100400</td>\n","      <td>0.001100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.025900</td>\n","      <td>0.000739</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=153, training_loss=0.1831420817735051, metrics={'train_runtime': 2124.4116, 'train_samples_per_second': 0.284, 'train_steps_per_second': 0.072, 'total_flos': 158655966382080.0, 'train_loss': 0.1831420817735051, 'epoch': 3.0})"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# Compute BERT embeddings for the query using the model fine-tuned on the larger dataset\n","query_embedding_FT_long = get_bert_embedding(query)\n","\n","# Compute BERT embeddings for each document in the corpus using the model fine-tuned on the larger dataset\n","corpus_embeddings_FT_long = [get_bert_embedding(doc) for doc in corpus]\n","\n","# Rank documents based on similarity to the query\n","rankings_BERT_FT_long = []\n","for idx, doc_embedding in enumerate(corpus_embeddings_FT_long):\n","    score = cosine_similarity(query_embedding_FT_long[0].cpu(), doc_embedding[0].cpu())\n","    rankings_BERT_FT_long.append((idx + 1, score))\n","\n","# Sort documents by similarity score in descending order\n","rankings_BERT_FT_long_srt = sorted(rankings_BERT_FT_long, key=lambda x: x[1], reverse=True)\n","\n","# Print document rankings\n","print(\"Document Rankings based on BERT embeddings (Fine-tuned on Larger Dataset):\")\n","for rank, (doc_idx, score) in enumerate(rankings_BERT_FT_long_srt, start=1):\n","    print(f\"Rank {rank}: Document {doc_idx} with score {score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSb7Nn_lO4KU","executionInfo":{"status":"ok","timestamp":1761742778181,"user_tz":-480,"elapsed":164,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"78330c7a-59e3-4ef0-87b6-5a3c64037376"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Document Rankings based on BERT embeddings (Fine-tuned on Larger Dataset):\n","Rank 1: Document 2 with score 0.7152009606361389\n","Rank 2: Document 1 with score 0.7067618370056152\n","Rank 3: Document 8 with score 0.6311885714530945\n","Rank 4: Document 3 with score 0.5422945618629456\n","Rank 5: Document 6 with score 0.5391206741333008\n","Rank 6: Document 9 with score -0.045311376452445984\n","Rank 7: Document 7 with score -0.12983421981334686\n","Rank 8: Document 10 with score -0.20751117169857025\n","Rank 9: Document 5 with score -0.24568398296833038\n","Rank 10: Document 4 with score -0.2604182958602905\n"]}]},{"cell_type":"code","source":["# Compute Average Precision (AP) for pre-trained model\n","\n","# Define relevance judgments (same as before)\n","qrel = {\n","    'q1': {\n","        'doc1': 1,\n","        'doc2': 1,\n","        'doc5': 1,\n","        'doc6': 1,\n","        'doc8': 1\n","    }\n","}\n","\n","# Define retrieval results with scores from pre-trained model\n","q1_pretrained = {\"doc\"+str(i+1): float(rankings_BERT[i][1]) for i in range(0,10)}\n","\n","run_pretrained = {\n","    'q1': q1_pretrained\n","}\n","\n","evaluator_pretrained = pytrec_eval.RelevanceEvaluator(qrel, {'map'})\n","results_pretrained = evaluator_pretrained.evaluate(run_pretrained)\n","ap_pretrained = results_pretrained['q1']['map']\n","print(f\"Average Precision (pytrec_eval) (Pre-trained): {ap_pretrained:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C79DTbFiO5zr","executionInfo":{"status":"ok","timestamp":1761742778229,"user_tz":-480,"elapsed":45,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"38bd8976-5c24-4ae4-8bdc-82b75dbb11a1"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Precision (pytrec_eval) (Pre-trained): 0.8850\n"]}]},{"cell_type":"markdown","source":["Based on the Average Precision scores, fine-tuning the BERT model on the larger dataset (Corpus_long.tsv, AP: 0.9000) resulted in slightly lower performance compared to fine-tuning on the smaller dataset (AP: 0.9667), but still outperformed the pre-trained model (AP: 0.8850). In this specific case, the increase in training data did not lead to better performance, suggesting that the quality and relevance of the smaller, carefully curated dataset might have been more impactful for this particular task, or that the larger dataset introduced noise."],"metadata":{"id":"pfN6gJ5KO8UJ"}},{"cell_type":"markdown","source":["# 4. Analysis"],"metadata":{"id":"EkbQFjr6Z7zV"}},{"cell_type":"markdown","source":["## 4.1 Visualizing The Distribution of Embeddings\n"],"metadata":{"id":"uTmlaAs1aenN"}},{"cell_type":"markdown","source":["Let's observe how fine-tuning change the documents and query are represented in the vector space."],"metadata":{"id":"ZJqSTsz6ao6S"}},{"cell_type":"code","source":["# Combine query and document embeddings (before fine-tuning)\n","all_embeddings_before = [query_embedding] + corpus_embeddings\n","# Combine query and document embeddings (after fine-tuning)\n","all_embeddings_after = [query_embedding_FT] + corpus_embeddings_FT\n","\n","# Concatenate all embeddings and move them to CPU for further processing\n","all_embeddings_before_tensor = torch.cat(all_embeddings_before, dim=0).cpu()  # Concatenate and move to CPU\n","all_embeddings_after_tensor = torch.cat(all_embeddings_after, dim=0).cpu()  # Concatenate and move to CPU\n","\n","# Create labels where 0 corresponds to the query, and the rest to documents\n","all_labels = [0] + example_labels  # Add a label for the query (e.g., 0)\n","\n","# Apply t-SNE to reduce the dimensionality of embeddings to 2D for visualization\n","tsne = TSNE(n_components=2, random_state=42, perplexity=5)\n","embeddings_before_2d = tsne.fit_transform(all_embeddings_before_tensor.numpy())  # Embeddings before fine-tuning in 2D\n","embeddings_after_2d = tsne.fit_transform(all_embeddings_after_tensor.numpy())  # Embeddings after fine-tuning in 2D\n","\n","# Extract query and document embeddings (before and after fine-tuning) for plotting\n","query_embedding_before_2d = embeddings_before_2d[0]  # Query embedding before fine-tuning\n","corpus_embeddings_before_2d = embeddings_before_2d[1:]  # Document embeddings before fine-tuning\n","\n","query_embedding_after_2d = embeddings_after_2d[0]  # Query embedding after fine-tuning\n","corpus_embeddings_after_2d = embeddings_after_2d[1:]  # Document embeddings after fine-tuning\n","\n","# Plot the embeddings before and after fine-tuning side by side\n","plt.figure(figsize=(12, 6))\n","\n","# Plot for embeddings before fine-tuning\n","plt.subplot(1, 2, 1)\n","scatter = plt.scatter(corpus_embeddings_before_2d[:, 0], corpus_embeddings_before_2d[:, 1], c=example_labels, label='Documents')  # Plot documents\n","plt.scatter(query_embedding_before_2d[0], query_embedding_before_2d[1], c='red', marker='*', s=100, label='Query')  # Highlight the query embedding\n","plt.title('Before Fine-tuning')  # Add title\n","\n","# Plot for embeddings after fine-tuning\n","plt.subplot(1, 2, 2)\n","scatter = plt.scatter(corpus_embeddings_after_2d[:, 0], corpus_embeddings_after_2d[:, 1], c=example_labels, label='Documents')  # Plot documents\n","plt.scatter(query_embedding_after_2d[0], query_embedding_after_2d[1], c='red', marker='*', s=100, label='Query')  # Highlight the query embedding\n","plt.title('After Fine-tuning')  # Add title\n","\n","# Add a legend to show which colors correspond to which labels\n","legend1 = plt.legend(*scatter.legend_elements(),\n","                    loc=\"lower left\", title=\"Classes\")\n","plt.gca().add_artist(legend1)\n","\n","# Display the plot\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"LMZBZmfqlk0c","executionInfo":{"status":"ok","timestamp":1761742778857,"user_tz":-480,"elapsed":626,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"8c3fee77-110b-43c7-8426-cb03aee5e4c0"},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["### ✏️ Observe the results above and discuss the following:\n","- According to the visualization, can you infer why fine-tuning leads to better IR results?\n","- What is t-SNE? What does it do?"],"metadata":{"id":"22zBUU76a1JB"}},{"cell_type":"markdown","source":["Fine-tuning enhances IR performance by creating better separation between relevant and irrelevant documents in the embedding space. Relevant documents cluster closer to the query after fine-tuning, indicating the model has learned more discriminative representations for relevance.\n","\n","t-SNE (t-Distributed Stochastic Neighbor Embedding) is a dimensionality reduction technique. It projects high-dimensional data (like BERT embeddings) into a lower-dimensional space (like 2D for plotting) while aiming to preserve local relationships between data points. This allows for visualization of how the embeddings are distributed."],"metadata":{"id":"SfdZXzT8PKfd"}},{"cell_type":"markdown","source":["## 4.2 Visualizing The Attention"],"metadata":{"id":"5XiaIjxhbj_y"}},{"cell_type":"markdown","source":["Let's use the following setence as example:"],"metadata":{"id":"JB56AdPvbnKi"}},{"cell_type":"code","source":["vis_sent = \"I pulled another all-nighter trying to finish this project. Coffee has become my best friend.\""],"metadata":{"id":"_T4X5GFuqgst","executionInfo":{"status":"ok","timestamp":1761742778865,"user_tz":-480,"elapsed":5,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["### Visualizing Attention from Fine-Tuned BERT"],"metadata":{"id":"eklPYZlFcKfl"}},{"cell_type":"code","source":["# Input text for visualization\n","input_text = vis_sent\n","\n","# Tokenize the input text\n","inputs = tokenizer.encode_plus(input_text, return_tensors='pt', add_special_tokens=True)\n","input_ids = inputs['input_ids']\n","token_type_ids = inputs.get('token_type_ids')\n","attention_mask = inputs.get('attention_mask')\n","\n","# Move inputs to the appropriate device (GPU if available)\n","input_ids = input_ids.to(device)\n","token_type_ids = token_type_ids.to(device) if token_type_ids is not None else None\n","attention_mask = attention_mask.to(device) if attention_mask is not None else None\n","\n","# Get model outputs, ensuring to get attention weights\n","# The key change is here: output_attentions=True\n","outputs = model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, output_attentions=True)\n","attention = outputs.attentions  # Access attention weights from the outputs\n","\n","# Get the tokens for visualization\n","tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n","\n","# Visualize attention\n","head_view(attention, tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":601,"output_embedded_package_id":"1dFIhEYRD3D5KeTDjgI13IHsGye4tr-r7"},"id":"LahvmWIjmqy0","executionInfo":{"status":"ok","timestamp":1761742781716,"user_tz":-480,"elapsed":2848,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"3f3d41db-3ca3-4026-f21d-8c8ab4006221"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### Visualizing Attention from Pretrained BERT"],"metadata":{"id":"CLzOvMracbEo"}},{"cell_type":"markdown","source":["Load the pretrained BERT again (`model` has now been fine-tuned)"],"metadata":{"id":"EjSrNLIDcdmO"}},{"cell_type":"code","source":["model_pre = BertForSequenceClassification.from_pretrained(model_name, num_labels=2, output_hidden_states=True)  # Adjust num_labels as needed\n","model_pre.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"_GL2UOL4nsLt","executionInfo":{"status":"ok","timestamp":1761742781850,"user_tz":-480,"elapsed":36,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"dacd7d0b-5155-4989-f67b-d9027b30d87d"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# Input text for visualization\n","input_text = vis_sent\n","\n","# Tokenize the input text\n","inputs = tokenizer.encode_plus(input_text, return_tensors='pt', add_special_tokens=True)\n","input_ids = inputs['input_ids']\n","token_type_ids = inputs.get('token_type_ids')\n","attention_mask = inputs.get('attention_mask')\n","\n","# Move inputs to the appropriate device (GPU if available)\n","input_ids = input_ids.to(device)\n","token_type_ids = token_type_ids.to(device) if token_type_ids is not None else None\n","attention_mask = attention_mask.to(device) if attention_mask is not None else None\n","\n","# Get model outputs, ensuring to get attention weights\n","# The key change is here: output_attentions=True\n","outputs = model_pre(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, output_attentions=True)\n","attention = outputs.attentions  # Access attention weights from the outputs\n","\n","# Get the tokens for visualization\n","tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n","\n","# Visualize attention\n","head_view(attention, tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":563,"output_embedded_package_id":"1-yrZr3ecUdTrB--Unbz4LPySMSK3JWcN"},"id":"T052qACFoZrF","executionInfo":{"status":"ok","timestamp":1761742787062,"user_tz":-480,"elapsed":5204,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"8cd74015-59cb-4127-9475-acbc1be24898"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### ✏️ Observe the results above and discuss the following:\n","- How can we read this diagram?\n","- What are the words that contribute the most to the relevance classification tasl?\n","- How are the attention scores change after fine-tuning?"],"metadata":{"id":"L-I-iSiLcpQS"}},{"cell_type":"markdown","source":["The attention diagram illustrates how different words \"pay attention\" to each other; stronger lines mean more important connections. Looking at different layers and heads shows different patterns.\n","\n","To figure out which words are most important for relevance, we look at how much the [CLS] token (used for sentence tasks) attends to other words, especially in later layers. Words with high attention from [CLS] are key for the classification. In our examples, words like \"all-nighter,\" \"project,\" and \"sleep deprivation\" terms are likely important.\n","\n","After fine-tuning, attention shifts. The model focuses more on words and phrases relevant to the task (finding relevant documents). This makes the fine-tuned model's attention more specialized for the task compared to the general pre-trained model."],"metadata":{"id":"YckRNW_mPptG"}},{"cell_type":"markdown","source":["# Assignment 2"],"metadata":{"id":"XAUxtE0LdA0h"}},{"cell_type":"markdown","source":["## 1. Discussion Questions"],"metadata":{"id":"ltfP-WmYkK61"}},{"cell_type":"markdown","source":["Answer the discussion questions above (those with ✏️ icon)."],"metadata":{"id":"MmWD4umXm3O3"}},{"cell_type":"markdown","source":["## 2. Diving Deeper into Model Fine-Tuning Analysis"],"metadata":{"id":"nUu28wAakRW7"}},{"cell_type":"markdown","source":["Refer to the following work that investigate BERT's behavior post fine-tuning:\n","\n","```\n","    Yichu Zhou and Vivek Srikumar. 2022. A Closer Look at How Fine-tuning Changes BERT. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1046–1061, Dublin, Ireland. Association for Computational Linguistics.\n","```\n","\n","In Section 4 Observations and Analysis, the authors show several obsevation on how fine-tuning changes BERT. Try to replicate their analysis in 4.1 to 4.3 and see if their discovery aligns with yours.<br />\n","You do not need to following everything step-by-step like using the exact same datasets or experiment setting. Focus on deriving similar insights."],"metadata":{"id":"5ZbuhUUqdCmr"}},{"cell_type":"code","source":["# Replicating Zhou & Srikumar (2022) Sections 4.1–4.3 with our lab data\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics.pairwise import pairwise_distances\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","\n","# Ensure datasets return PyTorch tensors for the required features\n","token_columns = ['input_ids', 'attention_mask']\n","if 'token_type_ids' in tokenized_dataset.features:\n","    token_columns.append('token_type_ids')\n","\n","tokenized_dataset.set_format(type='torch', columns=token_columns + ['label'])\n","tokenized_eval_dataset.set_format(type='torch', columns=token_columns + ['label'])\n","\n","def collect_model_outputs(model_ref, dataset):\n","    loader = DataLoader(dataset, batch_size=16)\n","    embeddings, logits, labels = [], [], []\n","    model_ref.eval()\n","    for batch in loader:\n","        labels.append(batch['label'].cpu().numpy())\n","        inputs = {k: batch[k].to(device) for k in token_columns if k in batch}\n","        with torch.no_grad():\n","            outputs = model_ref(**inputs, output_hidden_states=True)\n","        embeddings.append(outputs.hidden_states[-1][:, 0, :].cpu().numpy())\n","        logits.append(outputs.logits.cpu().numpy())\n","    embeddings = np.vstack(embeddings)\n","    logits = np.vstack(logits)\n","    labels = np.concatenate(labels)\n","    return embeddings, logits, labels\n","\n","def spatial_similarity(emb_train, emb_eval):\n","    train_dist = pairwise_distances(emb_train, metric='cosine')\n","    eval_dist = pairwise_distances(emb_eval, metric='cosine')\n","    tri_train = train_dist[np.triu_indices(train_dist.shape[0], k=1)]\n","    tri_eval = eval_dist[np.triu_indices(eval_dist.shape[0], k=1)]\n","    min_len = min(len(tri_train), len(tri_eval))\n","    if min_len == 0:\n","        return float('nan')\n","    tri_train = np.sort(tri_train)[:min_len]\n","    tri_eval = np.sort(tri_eval)[:min_len]\n","    if np.std(tri_train) == 0 or np.std(tri_eval) == 0:\n","        return float('nan')\n","    return float(np.corrcoef(tri_train, tri_eval)[0, 1])\n","\n","def centroid_stats(embeddings, labels):\n","    centroids, spreads = {}, {}\n","    for lbl in np.unique(labels):\n","        cluster = embeddings[labels == lbl]\n","        centroids[lbl] = cluster.mean(axis=0)\n","        spreads[lbl] = np.mean(np.linalg.norm(cluster - centroids[lbl], axis=1))\n","    pairwise = {}\n","    label_list = sorted(centroids.keys())\n","    for i in range(len(label_list)):\n","        for j in range(i + 1, len(label_list)):\n","            la, lb = label_list[i], label_list[j]\n","            pairwise[f\"{la}-{lb}\"] = float(np.linalg.norm(centroids[la] - centroids[lb]))\n","    return spreads, pairwise\n","\n","# Collect embeddings, logits, and labels for pretrained and fine-tuned models\n","train_pre_emb, train_pre_logits, train_labels = collect_model_outputs(model_pre, tokenized_dataset)\n","eval_pre_emb, eval_pre_logits, eval_labels = collect_model_outputs(model_pre, tokenized_eval_dataset)\n","train_ft_emb, train_ft_logits, _ = collect_model_outputs(model, tokenized_dataset)\n","eval_ft_emb, eval_ft_logits, _ = collect_model_outputs(model, tokenized_eval_dataset)\n","\n","# Section 4.1 style metrics\n","pre_train_acc = accuracy_score(train_labels, np.argmax(train_pre_logits, axis=1))\n","pre_eval_acc = accuracy_score(eval_labels, np.argmax(eval_pre_logits, axis=1))\n","ft_train_acc = accuracy_score(train_labels, np.argmax(train_ft_logits, axis=1))\n","ft_eval_acc = accuracy_score(eval_labels, np.argmax(eval_ft_logits, axis=1))\n","pre_similarity = spatial_similarity(train_pre_emb, eval_pre_emb)\n","ft_similarity = spatial_similarity(train_ft_emb, eval_ft_emb)\n","\n","# Section 4.2 probes: linear (logistic) vs non-linear (MLP) heads\n","logreg_probe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, solver='liblinear'))\n","mlp_probe = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(128,), max_iter=1000, random_state=0))\n","logreg_pre_acc = logreg_probe.fit(train_pre_emb, train_labels).score(eval_pre_emb, eval_labels)\n","mlp_pre_acc = mlp_probe.fit(train_pre_emb, train_labels).score(eval_pre_emb, eval_labels)\n","logreg_ft_acc = logreg_probe.fit(train_ft_emb, train_labels).score(eval_ft_emb, eval_labels)\n","mlp_ft_acc = mlp_probe.fit(train_ft_emb, train_labels).score(eval_ft_emb, eval_labels)\n","\n","# Section 4.3 geometry: intra- and inter-label distances\n","pre_spreads, pre_pairwise = centroid_stats(train_pre_emb, train_labels)\n","ft_spreads, ft_pairwise = centroid_stats(train_ft_emb, train_labels)\n","\n","print(\"Section 4.1 – Accuracy and train/test similarity\")\n","print(f\"Pre-trained  – train acc: {pre_train_acc:.3f}, eval acc: {pre_eval_acc:.3f}, train/test similarity: {pre_similarity:.2f}\")\n","print(f\"Fine-tuned   – train acc: {ft_train_acc:.3f}, eval acc: {ft_eval_acc:.3f}, train/test similarity: {ft_similarity:.2f}\\n\")\n","\n","print(\"Section 4.2 – Linear vs non-linear probes (eval accuracy)\")\n","print(f\"Pre-trained  – logistic: {logreg_pre_acc:.3f}, MLP: {mlp_pre_acc:.3f}\")\n","print(f\"Fine-tuned   – logistic: {logreg_ft_acc:.3f}, MLP: {mlp_ft_acc:.3f}\\n\")\n","\n","print(\"Section 4.3 – Label geometry on training embeddings\")\n","for lbl, spread in pre_spreads.items():\n","    print(f\"Pre-trained  label {lbl} avg intra-cluster distance: {spread:.3f}\")\n","for pair, dist in pre_pairwise.items():\n","    print(f\"Pre-trained  centroid distance {pair}: {dist:.3f}\")\n","print()\n","for lbl, spread in ft_spreads.items():\n","    print(f\"Fine-tuned   label {lbl} avg intra-cluster distance: {spread:.3f}\")\n","for pair, dist in ft_pairwise.items():\n","    print(f\"Fine-tuned   centroid distance {pair}: {dist:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"faiijKeTYZLJ","executionInfo":{"status":"ok","timestamp":1761742790568,"user_tz":-480,"elapsed":3462,"user":{"displayName":"David-Oliver Matzka","userId":"17699470839693386717"}},"outputId":"f773fe67-911c-4282-be3d-c37e1118642c"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Section 4.1 – Accuracy and train/test similarity\n","Pre-trained  – train acc: 0.433, eval acc: 0.350, train/test similarity: 0.92\n","Fine-tuned   – train acc: 1.000, eval acc: 1.000, train/test similarity: 0.90\n","\n","Section 4.2 – Linear vs non-linear probes (eval accuracy)\n","Pre-trained  – logistic: 0.950, MLP: 0.950\n","Fine-tuned   – logistic: 1.000, MLP: 1.000\n","\n","Section 4.3 – Label geometry on training embeddings\n","Pre-trained  label 0 avg intra-cluster distance: 5.139\n","Pre-trained  label 1 avg intra-cluster distance: 3.861\n","Pre-trained  centroid distance 0-1: 3.020\n","\n","Fine-tuned   label 0 avg intra-cluster distance: 5.190\n","Fine-tuned   label 1 avg intra-cluster distance: 3.063\n","Fine-tuned   centroid distance 0-1: 29.239\n"]}]},{"cell_type":"markdown","source":["## 💻 Assignment Submission 💻\n","Write your code and display the results in this Jupyter Notebook. Then, share this notebook and submit the link to this notebook to TronClass </br>\n","**Please ensure that the code is executed and the outputs are visible.**"],"metadata":{"id":"qg3WItTGjWqb"}}]}